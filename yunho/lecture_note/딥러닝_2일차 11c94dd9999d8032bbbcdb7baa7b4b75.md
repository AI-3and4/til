# 딥러닝_2일차

유형: 강의 기록
강의 날짜: 2024년 10월 11일
상태: 시작 전
주제: 딥러닝

---

0940

### 복습

https://drive.google.com/drive/folders/14Bd426TRr-_aWFb33D0_Li0LfwRB3bd9?usp=sharing

추가공유자료에 딥러닝 정리_1일차

### 2

- \\\\\ 기본구조는 2차원. \\\\셀
모델링을 위한 전처리
    - \\\\ 날리던지, 채워넣던지.
    비즈니스 의미를 담아야하는데. 이 자리에 이걸 넣는게 말이 되는지
    - 숫자여야 함. 그래서 가변수화함. 
    범주면 숫자로 바꿔야 함.
    모델은 수학식인데 이건 계산돼야 하고 그러려면 숫자여야 함.
    숫자\\\\ 의미
    원핫인코딩
    - 숫자의 범위 일치
    딥러닝은 스케일링이 필수
        - 정규화와 표준화는 언제 뭐 쓰냐
        웬만한 경우에는 크게 차이 없다. 이상치가 심하게 있다면 표준화 ㄱ
- 전처리하면 모델\\\\\\ 검증
- 데이터분석: \\\\ 패턴을 찾아서\\\ 연결
- 모델은 수학식으로 연결\\\\

- 모델 만들때 trainset으로 만들ㅇ
- 어느정도 적절한지 \\ valset으로 검증
- train와 val은 서로 섞음. 학습검증하고 섞고. 둘은 형제.
- test는 수능. 본적이 없어야 함. 실전. 모델 다 만들고 \\\\ 배포됐다 가정하고 최종 테스트 할 때. 마치 운영해서 지금 발생한 데이터나 다름없다고 생각하는 \\\\\
처음부터 떼어\\\ 데이터분석에서 사용하면 안돼.
- \\\\ 데이터 셋 하나로 \\\  한번 쪼개서 모델만들고 검증하지 말고
\\\\ 구간\\ 한번 나온 결과로 믿지 않고\\\\ 그냥 섞지 말고 정교하게 해보자. 모든 데이터가 한번씨;ㄱ은 val 해보자 → 교차 검증
\\\\ → k분할
이런 식으로 검증

### 3

- 개념, 전제조건, 성능
- 개념을 깊이 파면 수학식이 나옴. 너무 깊게 가지 말고 큰 틀에서 쉽게 이해해도 괜찮음.
- KNN
- Gradient Boost
    - 부스팅이란, 모델을 만들어 전체 타겟대비 이만큼의 오차. 첫 모델의 오차\\\ 간극을 줄이기 위해, \\\\ 세번째 는 이전의\\\ 모델을 계속 더해가는 모델을 부스팅 모델이라고 함.
        - 모델 몇개: n_estimators
        - ㅇㅇ: lr

### 5

- .fit() 하는 순간 열일
- 모델링의 목적은 가장 좋은 파라미터 찾기. ㅇㅊ하는데 가장\\ 오차가\\\\\
식의 구조와 찾아진 파라미터\\\\ \\
모델의 구조\\\\
우리가 찾는 게 아니라 .fit하면 모델이 찾아주는 것
- 찾아진 수학식으로 계산. \\\오차 계산
- \\\ optimizer. adam으로 통일.
조정했다면 가중치에 할당.
- 이후 부터 다시 계산하고, 오차 계산하고 반복 쭉
- feed-forward
back: 오차로부터 역으로
- 몇번반복할거야 ? : epochs

### 6

- 우리는 실전에서 이 그림을 볼 수 없어\\\\\\
- 우 그래프를 보게 되는데 이게 학습 곡선

### 7

- \\\\\\\ 동그라미가 노드
- dense
- 선마다 가중치가 붙고 절편값까지 붙음

c 03과-2 3모델링 모델1

.fit의 validation split\\\\\\\\\

검증
mae의 의미: 평균오차가 1이래 이 의미는 ?

세일즈를 예측하는데 판매량 천개정도 오차가 발생함.  1의 단위가 천이라는 것.

mape가 너무 크다. 왜 ?
mape\\\\ 분모가 0이라면 계산 될 수 없으니까 계산은 되게 아주 작은 수를 넣자.
이럴 때 mape가 엄청 크게 나와. 이럴 때 이거 볼 필요 없음.
나는 95141471295897.84 나왔으ㅜㅁ.

설문의 질문)

1. 은닉층을 쌓아서 선형이 비선형이 됐다고 하셨는데
저희가 직접 그 곡선을 확인할 수 있는 방법이 있나요 ????
2. Sequential의 Input 안에 shape=(nfeatures,) 이렇게 1차원으로 넣었는데 이해가 잘 되지 않습니다. 저희 데이터는 2차원의 DF인데 왜 1차원으로 넣게 되는 건가요 ?
→ 아 대충 이해했어
대입할 때 한줄을 대입하잖아
3. model.fit() 안에 validation_split을 지정하면 결과에 loss 뿐만 아니라 val_loss도 함께 epochs 수만큼 주루룩 결과가 뜨는데 이 과정이 머신 러닝의 k분할 교차검증과 비슷한 과정인가요 ?? 즉, 다시 말해 반복 횟수마다 랜덤하게 validation set을 설정하는 것인지, epochs 수만큼 분할하여 진행하는 것인지 궁금합니다.
loss와 val_loss의 정확한 의미도 궁금합니다.

---

1040

c 모델2

- 레이어의 수와 노드의 수는 어케 찾아 ? 우리가 알아서
대체로는 input에서 줄이는 방향으로
- 시그모이드는 은닉층에서 잘 안 씀\\\ 기울기의 \\\\

추가실험은 나중에 알아서 ㄱ

## Chapter 4. Feature Representation

### 51

- 인공지능이 나날이 발전하고 있는데 내부에서 어떤 일이 일어나는지 모른다는게 두렵다.
여기서 내부가 히든 레이어.
그 구조 안에서 어떤 일이 일어나느지 속속들이 알 수가 없다는 게 \\\
- \\ 특별한 구조.

### 52

- 어제까지 했던 구조는 모든게 연결됐던 구조. 지금 구조는 뚝 짤려있음.

### 57

- 집값햇 = 0.7내부 + 0.3외부 + bias
- 중간 히든 레이어에서 새로운 정보, feauter, 변수로 재구성 했어.
- 예전에 카시트에서 comprice - price = 가격경쟁력 했듯이.
- 원래 있던 정보가 내부요인이라는 \\\\한단계,\\\ 추상화된 
구체적인 raw 데이터가 모여서 의미 있는 추상화된 정보고 만들어졌음.

### 58

- 히든레이어 추가의 의미란, \\\\\\
무슨 일이 일어나냐\\\\\\ 구체적인 정보가 중간의 어떤 정보고 \\\\ 집값을 예측하는 \\\\\ 중간 과정 중에서 좀더 추상화된\\\ 특징을 잘 도축\\\ 생성해낸다.
- 세부적인 정보가\\\ 추상화된 정보로 만들어지는\\\\\\ 구성할 수 있다.
- 새롭게 표현했다 그래서 feature representation\\ feature engineering\\

### 59

- ML: fe\\\\\ comprice
- DL: 중간 과정을 히든 레이어가 처리할 거야 라고 기대하고\\\\\
- 사람이 fe하던 것을\\
fe이란, \\\
- 수족구발병 예측하는데 기온, 최고, 최저 변수를 썼는데 일교차도 중요하다는 것을 알게 되어 최고-최저로 일교차 변수를 만들었음.
- 일교차라는 정보가 dl\\\\ 믿음이 필요하다.
여기에 속해있는 가중치들이 오차를 최소화\\ 하기
중간 과정에서 그런 일들이 있을 거라고 믿\\\\\\

## Chapter 5. 딥러닝 모델링 이진분류

### 61

- 딥러닝 구조도 큰 틀에서 보면 하나의 함수
- 함수란 x를 받아서 y로 변환 → 입력을 출력으로 변환 → 함수는 변환 !

### 62

- 이론적으로 f(x)값은 음의 무한대부터 양의 무한대임.
- 우리 목적은 생존 여부. 결과가 0, 1로 나와야해.

### 63

- 시그모이드 함수 (로지스틱회귀 함수)에 넣어 !
x축은 음의무한대~양의무한대 / y축은 0 ~ 1
- \\\\ output layer에 activation func\\\\

03과 3\\\\\

05과-1

출력층에 activation func이 sigmoid로 돼있어
0과1로 변환해주는 함수
시그모이드 함수 정도는 외우자.

두가지 차이점

- 출력층에 act이 필요해 이진분류에는 시그모이드
안 쓰면 이 출력값은 무한대니까. 이걸 0과1 사이 값으로 변환해줘야하까
- loss function이 binary_crossentropy !!

### 65

- 와이
와이햇: 시그모이드 통과했으니까 0~1 값
- 교차표가 우리가 원하는 바

### 66

- x축이 와이햇

이 부분 전반적으로 다시 보자. lossfunc이 뭔지도 다시 보고

똑같은 그래프로\\\\\\ 

---

1140

- \\\\\\\ 첫부분 다시 쭉 .. 정리해주고 있음..
- 같은 함수를 \\\ 적용\\\

### 68

- 이 식 ML할 때 봤었음. log loss !!!!!!!

### 69

- 예측하면 확률값으로 나와. 그래서 잘라야해.
- 바꿔준다\\\\\\\

c

- 이진분류의 출력층은 activation이 시그모이드
- loss function은 bce
- 학습 결과 가\\\ 예측할 때 \\ 쪼개\\ 그래야 평가할 수 있어

stratify: 층화추출\\\\\\\\\ 데이터 양이 좀 되면 꼭 필수적인 옵션은 아님

activation이 있는 노드는 세로줄 긋고 우측에 activationfunc 그림 간단히 그림
sig는 s자, relu는 위로 꺾인 그림

& epoch50으로 한번 할때 이쁜데 그 이후로 100 한번 하면 과적합인듯 ??? 그래프 한번 봐봐

\\\\\\에포크 하나 끝날 때마다 따로 떼어놓은 거
loss는 나머지 80퍼센트로\\\\\\

### 70

- 확진자: 진단키트로 검사했더니 양성이 나온 5000명
이중에는 실제로 감염된 사람과 아닌 사람이 있음.
실제 감염: 잘 맞췄네 (TP)
아닌 사람: 틀렸네 (위양성,FP)
- 음성 나온 15000명 (FN + TN)
- 민감도, 특이도 관점..?\\\\\
- 재현율과 정밀도만 본대.
- 재현율 (실제 관점)
    - 감염 관점: TP/TP+FN
- 정밀도 (예측 관점)
    - 양성 관점: TP/TP+FP

- 기계 고장 예측 (0이 정상, 1이 고장)
1r과 1p 중 뭐가 중요해 ?
r의 입장: \\\
p의 입장: 니가 예측했으면 맞춰야지

### 71

- 둘다 중요한 거 아니야 ? 평균 내 → f1
산술평균이 아니라 조화평균

c 05과-1 5.딥러닝3

질) 혹시 loss 에 accuracy_score를 사용하는 경우도 있을까요?

\\\\\\

질) 

epoch 18 에 train,val_loss 가 유사하고 이후로 train_loss 는 감소하지만 val_loss 가 증가하는 경우 epoch 18 이후의 학습은 어떤 의미가 있는건가요?

→ 과적합과 연관

---

1330

히든 레이어와 activation func\\\\ 선형이 비선형으로\\\\\

xor문제 검색하면\\\\\\\ → 추가 자료에 업로드 할 예정

y가 1일때 1에 가까울수록 y가 0일때 0에 가까울수록 오차를 적게\\\

\\지금 이 설명 정리해보자

- val은 수평 train은 떨어지면서 차이가 벌어지는경우\\\\
\\\\ 학습 데이터는 계속 좋\\\ 데이터를 외워버렸어
너무 학습용 데이터에 과하게 맞춰졌어. 학습용데이터에 과적합. 공부하다 미침. 그거만 풀줄 알아. 조금만 응용되면 못 풀어

질) 히든레이어는 왜 relu사용하는지 다시 말씀해주실수있나요
acti 쓰면 \\\\\\\\
초창기 activation은 스텝함수\\\\\\\\\\\\\\\\\

추가자료의 가중치 업데이트 146

y: loss, x:가중치\\\\\\\\\\\\\\\\\ 미분을 할 수 있어야 한다

시그모이드 미분하면 정규분포 형태
0에 멀어질수록 기울기 소실(vanishing gradient) 문제 때문에 다양한 연구가 있었음. 기울기 유지되면서\\\\\ 비선형\\\ 이게 relu

& 미분 가능 조건 뭐였더라

relu 선형 아님??? 비선형으로 만들어준다며. 꺾였잖아 비선형.\\\\\\\\\\ 선형성이 깨졌음.

성능을 올리기 위해서라면 activation 을 건드리기 보다 다른 걸 손보는게 나음.

### 72

c 05과-2 종합실습

clear_session 하면 변수 nfeatures 사라짐 다시 선언해야해

(50, 10, 1), (50, 25, 10, 5, 1) 둘다 과적합 지림…..뭐임

노드수는 2^n 이든 아니든 안 중요하지만 관습적으로 2^n으로 함.

큰 모델이라는 것은 정교, 정확하\\\\\\
적당히 커야해. 얼만큼 적당히 ? 그건 해봐야해

metrics=[’accuracy’]

하나의 에포크마다, cross\\\\ lossfunction은 아니지만 평가\\\\ 함께 측정

train의 loss는 다 맞혔어

val은 성능이 좋아지다가 어느 순간 막 올라가 → 과적합
과하게 학습용ㄷ0이터에 fitting됐어.

accuarcy score 높다고 해서 다\\\\\\\\\\\
1의 관점에서 보면 .. 형편없어.

위 그래프의 오차 계산은 lossfunction인 bce로 했어.
오차가 증가했다고 해서 accuacy도 올라갔다가 팍 떨어지지 않을수 있어.

bce에 의한 해석과 accuracy에 의한 해석이 항상 일치하지는 않아.

---

1430

stratify

y.value_counts(normalize=True) : 0.84, 0.16 비율로 돼있음.\\\\\

모델의 복잡도는 과소, 과대적합에 영향을 준다

knn의 경우, k값이 크면 단순해지고, 작으면 복잡해진다.

dt의 경우 max_depth이 크면 복잡해지고, 작으면 단순해진다.

dl의 경우,\\\\\\\\\\\\\\\

val_err가 다시 올라가는 지점 전까지로 epoch를 수정…. → 이것도 월요일 (early stopping) 지금은 과적합된 채로

\\\\알고리즘은 로스를 줄이는 방향으로 학습
\\\\ 평균으로 계산해. 개별적인거 관심없고 평균만

만약 0은 0.99, 1은 0.01이라면, 1이 아주 적다면 학습을 어떻게 하냐. 1에 대한 학습\\\\\\ 모델이 모든 경우에 다 0이라고 예측해버리는 상황 발생. 여기서 딜레마. 관련 자료를 이상탐지 자료 안에 포함시켜놨음.

소수 클래스에 해당되는 값이 우리 관심사가 되는 경우가 많음.

이탈고객 관련. 이탈고객에 관심 있지.
제조공정에서 \\\\ 불량에 관심 있지.
사기 거래, 사기 거래에 관심 있지.
고장에 관심 있지.

다수를 마\\\ 소수는 다 틀려. 하지만 우리 관심은 소수.

다수가 990건, 소수가 10건이라면, 990건을 조절해보자. 다시 데이터를 뽑아보자, 샘플링해보자 → resampling.

분류모델은 클래스 불균형이\\\\\

resamplign의 몇가지 유형: 
다운샘플링(언더샘플링) 990건을 10건으로
업샘플링(오버샘플링): 10건을 990건으로.
다운은 뽑으면 되는데 업은 어케함? 두가지
1뻥튀기: 뽑은걸 또 뽑고 또 뽑고 이런식
2스모트: 데이터 세건 있다면 그럴싸하게 뽑아야지. 생성. 데이터끼리 선을 그어서 사이값으로 생성. (일종의 augmentation(증식))

클래스 불균형일때 as만 보면 큰일나

\\\\\\\\\\\\\\학습데이터 갖고, 검증 \\\\\
학습 데이터는 과장된 월드, 쓸때는 그냥 val 데이터로. val을 리샘플링하면 큰일나

1r이랑 f1 좀 올랐음
과적합도 사라졌는데

질) 데이터 클래스간 불균형 문제를 해결하기 위해 딥러닝에서는 class balanced loss와 같은 손실함수를 사용한 방법도 있긴 합니다.

\\\\\\\

### 74

crossentropy 는 정보이론 분야에서 나온\\

로그로스\\\\

ReLU (Rectified Linear Unit)

## Chapter 6. 딥러닝 모델링 다중분류

이진분류는 0이냐 1이냐.

다중분류는 3개 이상을 분류.

### 76

출력층에 노드 하나라면 \\\\\\

노드 하나로 두고 0,1,2 지정하는 건 말이 안되지\\\\\

교차 엔트로피랑, 소프트맥스 둘다 ML에서 했었어

### 77

e: 자연상수

소프트맥스의 특별한 형태가 바로 시그모이드. → 참조자료

이중에 가장 큰 값을 부드럽게 찾아줘.

### 78

실제값 1인거에 대해서만 오차 계산을 한다\\\\crossentropy\\\\\

질) 혹시 실제값이 1이 2개 이상인 경우도 가능할까요?

→ 있음. 사람 고양이 새 분류하는 경우.
사람도 있고, 새도 있는 경우라면? 있음. 이런게 multi-label

### 79

- y에 대한 특별한 전처리가 필요. 두가지 중 편한 거 ㄱㄱ
- 1 정수 인코딩(라벨 인코딩)
이때 loss func는 sparse cce
- 2 원핫인코딩 (가변수화하는 거랑 똑같음)
loss func은 cce
- 둘다 수학적으로 똑같아. 성능 차이 없어.

c 06과-1

정수 인코딩은 항상 0부터 시작해.
매핑해도 되고, LabelEncoder 써도 되는듯

---

1530

y_val[:5]

Species
47	0
73	1
74	1
129	2
67	1

pred[:5]

```
array([[9.7031665e-01, 2.9478921e-02, 2.0443105e-04],
       [1.7077815e-02, 7.9121983e-01, 1.9170232e-01],
       [2.0477487e-02, 7.1642733e-01, 2.6309511e-01],
       [1.0789161e-03, 3.9249024e-01, 6.0643077e-01],
       [4.1804548e-02, 8.6781615e-01, 9.0379238e-02]], dtype=float32)
```

### 81

- 얘도 -로그 갖고 계산함.
- 가장 큰 0.97을 로그에 넣고\\\\\\
- 데이터의 형태가 다를 뿐이지\\\\\\
로그 로스

### 84

- 후처리 해야한다
- 가장 큰 값의 인덱스를 찾아라. → argmax()
- 이전에 이진분류는 np.where 했듯이

c

인코딩: 원본을 어떤 목적을 갖고 변형

디코딩: 어떤 목적을 갖고 원본으로 복원

암호화-복호화, QR, 압축-압축해제

softmax, cce, argmax후처리 ← 이 세갠가 ?

output layer의 노드가 세개니까 숫자가 세개 나오는 것. 하나의 행\\\\
softmax로 했기 때문에 그 합은 1
가장 확률이 높은 \\\\\ 어떻게 찾냐 argmax로.

1. 모델링2

np.where로 후처리할때 pred>0.5했음. 이때 0.5를 cut-off value라고 하는데 이걸 갖고 튜닝하는 경우도 있음. 그냥 일반적으로 .5 쓴다. 조정할 수 있기는 하다

학습 곡선에서 오차가 요동치면서 내려가는 것의 대표적인 요인은 lr이 커서.
근데 주의 사항, 보폭을 줄이면 걸음수 늘려야지. lr 줄이면 epochs 늘려.
학습곡선이 부드러워짐 - 근데 부드러워\\\\\\\\\\\\\ 로스 갖고 판단해야한다

참조

\\\\\ values 하면 np.array가 된다

원핫인코딩하면 lossfunc은 cce

pred도, y_val도 argmax()

### 83

error 식은 한번 읽어봐라 ~

---

1630

c 06과-2

시그모이드와 소프트맥스 추가 설명은 p152

validation_split\\\\\ 뭐 못 들었어

학습에서 오류가 나는 건,\\데이터 구조가\\

model1의 as가 0.53
틀린 애들 중 덩치 큰 애 두개

원래 2인데 1이라 예측한 애 105, 원래는 3인데 2이라 예측한 애 186

as 좀 낮긴 하지만 틀리긴 해도 \\\\\\\\\\\ as만 보고 땡하고 끝내는 건 안돼\\\

4는 하나도 못 맞췄고 1은 성능이 낮아. 데이터가 너무 적어서. (내껀 하나 맞췄음)

4의 경우 실제 4인데 주로 2,3이라고 ㅎ0ㅐㅆ음 
내 모델 2,3의 에러 문구가 이런거임. 강사님꺼랑 같아.

### 88

\\\\\ 히든레이어의 목적: 딥하게 학습, 비선형\\\\\\\\\\\\\\\